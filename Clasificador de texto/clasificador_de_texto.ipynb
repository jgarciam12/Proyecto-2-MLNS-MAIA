{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bf9a943-01ce-46b0-bd65-7a113677f46d",
   "metadata": {},
   "source": [
    "# Universidad de los Andes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1eb33e-5ab7-4a7f-b79c-d48f093e80fd",
   "metadata": {},
   "source": [
    "Proyecto presentado por:\n",
    "* Javier Camilo Garcia Matos\n",
    "* Daniel Felipe Caro Torres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f981f0f3",
   "metadata": {},
   "source": [
    "## Proyecto: Claficador de texto según las 17 ODS\n",
    "\n",
    "El objetivo del proyecto es desarrollar una solución, basada en técnicas de procesamiento del\n",
    "lenguaje natural y machine learning, que permita clasificar automáticamente un texto en los\n",
    "17 ODS, ofreciendo una forma de presentación de resultados a través de una herramienta de\n",
    "fácil comprensión para el usuario final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25429c22-7d5f-4daf-87d0-c5cac81cd302",
   "metadata": {},
   "source": [
    "### Planteamiento del problema y solucion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcf383a-062f-421c-b2a2-ac07c33a58b9",
   "metadata": {},
   "source": [
    "En el marco de los Objetivos de Desarrollo Sostenible (ODS) de la ONU, muchas organizaciones buscan clasificar grandes volúmenes de texto para entender qué partes de la información corresponden a cada objetivo: fin de la pobreza, salud y bienestar, educación de calidad, igualdad de género, etc. Para ello, se pueden usar técnicas de procesamiento de lenguaje natural (NLP) y machine learning, evitando el análisis manual de miles de documentos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfb22dd-ff8f-4fa2-8638-0cd08cd4f08f",
   "metadata": {},
   "source": [
    "###### Este notebook presentará el desarrollo paso a paso de un clasificador entrenado en textos en español, siguiendo el flujo:\n",
    "\n",
    "1. Importación y exploración de datos\n",
    "2. Separación de train/test/validación\n",
    "3. Preprocesamiento (limpieza, stopwords, stemming, etc.)\n",
    "4. Vectorización (TF-IDF)\n",
    "5. Reducción de dimensionalidad (SVD)\n",
    "6. Entrenamiento y selección de modelo\n",
    "7. Evaluación (métricas y ejemplos concretos en un conjunto de prueba)\n",
    "8. Conclusiones\n",
    "\n",
    "Se finaliza mostrando la clasificación de algunos ejemplos de test, verificando la utilidad del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1663ee00-0760-447b-b747-988631af73a8",
   "metadata": {},
   "source": [
    "#### 1. Importación y exploración de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "96046449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer # SnowballStemmer para espa;ol\n",
    "\n",
    "# entrenar/validar el modelo\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Representación de textos\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Reducción de dimensionalidad\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "#-----------------\n",
    "\n",
    "# Clasificadores \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Para métricas de evaluación\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Para pipeline y búsqueda de hiperparámetros\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "nltk.download('stopwords')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ad79b5-1ac4-4e44-80df-b6fbbac5bda0",
   "metadata": {},
   "source": [
    "##### Carga y exploración de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f7c19bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textos</th>\n",
       "      <th>ODS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3214</th>\n",
       "      <td>Las organizaciones de mujeres de la sociedad c...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9316</th>\n",
       "      <td>Los Estados miembros de la Unión Europea se ha...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7521</th>\n",
       "      <td>ResumenLas reglas de jurisdicción e inmunidad ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6609</th>\n",
       "      <td>En la mayoría de los países, la redistribución...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264</th>\n",
       "      <td>Este capítulo explora cómo una red de defensor...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 textos  ODS\n",
       "3214  Las organizaciones de mujeres de la sociedad c...    5\n",
       "9316  Los Estados miembros de la Unión Europea se ha...   16\n",
       "7521  ResumenLas reglas de jurisdicción e inmunidad ...   16\n",
       "6609  En la mayoría de los países, la redistribución...   10\n",
       "4264  Este capítulo explora cómo una red de defensor...   16"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Train_textosODS.xlsx')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4b9ecc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de los datos: (9656, 2)\n"
     ]
    }
   ],
   "source": [
    "print('Tamaño de los datos:',df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1ffec8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de datos nulos:\n",
      "textos    0\n",
      "ODS       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Cantidad de datos nulos:')\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "414b489e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de datos duplicados:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print('Cantidad de datos duplicados:')\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbfd096-6423-4e03-9ca2-5ca412f32440",
   "metadata": {},
   "source": [
    "#### 2. Separación de train/test/validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9df9c75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de datos de entrenamiento: 7724\n",
      "Cantidad de datos de prueba: 1932\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size = 0.2, random_state=0)\n",
    "print('Cantidad de datos de entrenamiento:',len(df_train))\n",
    "print('Cantidad de datos de prueba:',len(df_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1c86ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train['textos']\n",
    "y_train = df_train['ODS']\n",
    "\n",
    "x_test = df_test['textos']\n",
    "y_test = df_test['ODS']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8f153e-485a-45bb-a17d-09e7529cf51c",
   "metadata": {},
   "source": [
    "#### 3. Preprocesamiento (limpieza, stopwords, stemming, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8265f539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    stemmer = nltk.SnowballStemmer('spanish')  # Stemming en español\n",
    "    spanish_stops = set(stopwords.words('spanish'))\n",
    "    \n",
    "    # minúsculas\n",
    "    text = text.lower()\n",
    "\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    # remover stopwords\n",
    "    tokens = [word for word in tokens if word not in spanish_stops]\n",
    "    # stemming\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02698347-8b1f-45fc-8ff6-dbd017c91021",
   "metadata": {},
   "source": [
    "#### 4. Vectorización (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "150d681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(preprocessor=text_preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e7441b-724c-4f5a-a097-539af6731107",
   "metadata": {},
   "source": [
    "#### 5. Reducción de dimensionalidad (SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbf09b1-4968-4523-a77f-531b27e30661",
   "metadata": {},
   "source": [
    "Usamos TruncatedSVD para reduccoin de dimensionalidad, ya que lo consideramos más adecuado para datos dispersos, como los generados por TF-IDF, ya que no requiere centrar los datos y puede trabajar eficientemente con matrices dispersas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e2d4d7ae-2780-4fc8-b2cc-c1f3b7836091",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsvd = TruncatedSVD(n_components=100, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69625fb-c481-45bc-b932-6877435d1bfe",
   "metadata": {},
   "source": [
    "#### 6. Entrenamiento y selección de modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04705dfd-1e27-4e27-a062-9a25e55fe9df",
   "metadata": {},
   "source": [
    "Escogemos Regresión Logística para multiclase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0528e085",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(\n",
    "    multi_class='multinomial',\n",
    "    solver='saga', \n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d7950151",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline([\n",
    "    ('tfidf', vectorizer),\n",
    "    ('svd', tsvd),\n",
    "    ('clf', clf)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e31a106-ca66-46a8-a133-7f7db2f94d88",
   "metadata": {},
   "source": [
    "predecir en validación/test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea125901-95ec-4bc9-b54c-34770a997333",
   "metadata": {},
   "source": [
    "##### Búsqueda de hiperparámetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0acdf56-4ad8-4574-b19b-dafefbbabe6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'svd__n_components': [50, 100, 200],\n",
    "    'clf__C': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    full_pipeline, \n",
    "    param_grid, \n",
    "    scoring='accuracy', \n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "print(\"Mejores hiperparámetros:\", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a891d7d-92b0-4936-848e-895e6fca10b1",
   "metadata": {},
   "source": [
    "#### 7. Evaluación (métricas y ejemplos concretos en un conjunto de prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da53482-2705-40e6-bd3b-529f4bcee0d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Evaluación en conjunto de prueba:\")\n",
    "y_test_pred = best_model.predict(x_test)\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c301c2c-584b-4fdd-a724-2a336ba70878",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"Matriz de confusión:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5628912e-b87f-4095-869a-0e93ff7f8a25",
   "metadata": {},
   "source": [
    "##### Ejemplos concretos de prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb795729-8e84-4f74-9ee8-1c91f8ceafa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "sample_indices = random.sample(list(df_test.index), 4)\n",
    "for idx in sample_indices:\n",
    "    raw_text = df_test.loc[idx, 'textos']\n",
    "    true_label = df_test.loc[idx, 'ODS']\n",
    "    pred_label = best_model.predict([raw_text])[0]\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"Texto:\\n{raw_text}\\n\")\n",
    "    print(f\"ODS real: {true_label}\")\n",
    "    print(f\"ODS predicho: {pred_label}\")\n",
    "    print(\"=\"*60, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a1ac96-e6f5-48d6-9b9d-730788b394e1",
   "metadata": {},
   "source": [
    "#### 8. Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade79518-1e5a-4007-adac-4730c020db2f",
   "metadata": {},
   "source": [
    "##### 1) Preparacion de datos y reduccion de al dimensionalidad:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f891cf8-db45-4be3-9fd1-9c5d266adca0",
   "metadata": {},
   "source": [
    " - Se ha justificado el uso de TF-IDF por resaltar términos relevantes \n",
    "     y SVD por condensar la información en menos dimensiones (50, 100 o 200), \n",
    "     mejorando tiempo de entrenamiento y reduciendo ruido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e03573b-de50-470a-8af1-c113d89bcfbb",
   "metadata": {},
   "source": [
    "##### 2) Resultados del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b797fe7-4d4d-409a-a796-0ee9219f127d",
   "metadata": {},
   "source": [
    "El modelo alcanzó un desempeño destacado al clasificar automáticamente textos en relación con los distintos ODS. En promedio, la exactitud rondó alrededor del 86–87% en el conjunto de prueba, lo cual indicó que la mayoría de las clases fueron reconocidas con buenos valores de precisión, recall y f1-score. Sin embargo, se evidenció que ciertos ODS con menos ejemplos disponibles presentaron resultados más modestos, lo que sugirió la necesidad de recopilar más datos o ajustar algunas fases del preprocesamiento para mejorar aún más la robustez del modelo.\n",
    "\n",
    "Asimismo, la reducción de dimensionalidad mediante SVD contribuyó a una mayor eficiencia y a evitar el sobreajuste en un espacio inicial muy extenso producto de la representación TF-IDF. Esto, sumado a la búsqueda de hiperparámetros a través de GridSearchCV, permitió afinar los valores óptimos para la regresión logística, logrando un equilibrio entre complejidad y rendimiento. En última instancia, el uso de métricas globales y de ejemplos concretos demostró la solidez del enfoque para clasificar grandes volúmenes de texto en español, brindando una base confiable para su aplicación en contextos reales de análisis y toma de decisiones sobre los ODS.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab083d7c-18fb-4e30-a522-0a360feab06f",
   "metadata": {},
   "source": [
    "##### 3) Ejemplos reales:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf1aa19-2a49-48de-8fdf-1aaa54e0362b",
   "metadata": {},
   "source": [
    "   - Se mostraron 4 textos del conjunto de prueba, junto a la \n",
    "     etiqueta real y la predicción, evidenciando la utilidad del modelo \n",
    "     para clasificar nuevos documentos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
